import os
import streamlit as st
from openai import OpenAI
import json
import base64
from PIL import Image
import io
import numpy as np
import pandas as pd
from datetime import datetime
import uuid
from pathlib import Path
import logging
import tempfile
import shutil

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# ãƒšãƒ¼ã‚¸è¨­å®š
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
st.set_page_config(
    page_title="ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒŠãƒ¬ãƒƒã‚¸æ§‹ç¯‰ãƒ„ãƒ¼ãƒ«",
    layout="wide"
)

# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯
try:
    import pdf2image
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False
    st.warning("pdf2image ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚PDFå‡¦ç†æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")

try:
    import pytesseract
    OCR_SUPPORT = True
except ImportError:
    OCR_SUPPORT = False

# CADå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import ezdxf
    from matplotlib import pyplot as plt
    from matplotlib.patches import Circle, Rectangle, Polygon
    DXF_SUPPORT = True
except ImportError:
    DXF_SUPPORT = False
    st.info("ezdxf/matplotlib ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚DXFå‡¦ç†æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")

try:
    import trimesh
    STL_SUPPORT = True
except ImportError:
    STL_SUPPORT = False
    st.info("trimesh ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚STLå‡¦ç†æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")

try:
    import cadquery as cq
    STEP_SUPPORT = True
except ImportError:
    STEP_SUPPORT = False
    st.info("cadquery ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚STEPå‡¦ç†æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")

# ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç”¨
try:
    import faiss
    from rank_bm25 import BM25Okapi
    # Sudachiä½¿ç”¨
    from sudachipy import tokenizer
    from sudachipy import dictionary
    ADVANCED_SEARCH = True
    TOKENIZER_TYPE = "sudachi"
except ImportError:
    try:
        # MeCab fallback
        import MeCab
        ADVANCED_SEARCH = True
        TOKENIZER_TYPE = "mecab"
    except ImportError:
        ADVANCED_SEARCH = False
        TOKENIZER_TYPE = None
        st.info("é«˜åº¦æ¤œç´¢æ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™ï¼ˆæ¨å¥¨: sudachipy, ã¾ãŸã¯ faiss + rank-bm25 + mecab-python3ï¼‰")

# è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
os.chdir(current_dir)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('multimodal_kb_builder')

# å®šæ•°
GPT4O_MODEL = "gpt-4.1"
EMBEDDING_MODEL = "text-embedding-3-large"
EMBEDDING_DIMENSIONS = 1536  # ã‚³ã‚¹ãƒˆåŠ¹ç‡åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3072â†’1536ï¼‰
SUPPORTED_IMAGE_TYPES = ['jpg', 'jpeg', 'png', 'bmp', 'tiff', 'webp']
SUPPORTED_DOCUMENT_TYPES = ['pdf']
SUPPORTED_CAD_TYPES = ['dxf', 'stl', 'ply', 'obj', 'step', 'stp', 'iges', 'igs', '3ds']

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
DATA_DIR = Path(current_dir) / "multimodal_data"
DATA_DIR.mkdir(exist_ok=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'processed_images' not in st.session_state:
    st.session_state.processed_images = {}
if 'current_editing_id' not in st.session_state:
    st.session_state.current_editing_id = None

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—
@st.cache_resource
def get_openai_client():
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        return OpenAI(api_key=api_key)
    except Exception as e:
        st.error(f"OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def encode_image_to_base64(image_file):
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
    try:
        if hasattr(image_file, 'type') and image_file.type == "application/pdf":
            if not PDF_SUPPORT:
                st.error("PDFå‡¦ç†ã«ã¯pdf2imageãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™")
                return None
            images = pdf2image.convert_from_bytes(image_file.read())
            if images:
                buffered = io.BytesIO()
                images[0].save(buffered, format="PNG")
                image_file.seek(0)
                return base64.b64encode(buffered.getvalue()).decode('utf-8')
        else:
            image_file.seek(0)
            image_bytes = image_file.read()
            image_file.seek(0)
            return base64.b64encode(image_bytes).decode('utf-8')
    except Exception as e:
        logger.error(f"ç”»åƒbase64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ç”»åƒã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def process_dxf_file(dxf_file):
    """DXFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ç”»åƒã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    if not DXF_SUPPORT:
        return None, {"error": "DXFå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
    
    try:
        dxf_file.seek(0)
        with tempfile.NamedTemporaryFile(suffix='.dxf', delete=False) as temp_file:
            temp_file.write(dxf_file.read())
            temp_file_path = temp_file.name
        dxf_file.seek(0)
        
        doc = ezdxf.readfile(temp_file_path)
        msp = doc.modelspace()
        
        entities_info = {
            'lines': [],
            'circles': [],
            'arcs': [],
            'texts': [],
            'dimensions': [],
            'blocks': []
        }
        
        for entity in msp:
            if entity.dxftype() == 'LINE':
                entities_info['lines'].append({
                    'start': tuple(entity.dxf.start[:2]),
                    'end': tuple(entity.dxf.end[:2])
                })
            elif entity.dxftype() == 'CIRCLE':
                entities_info['circles'].append({
                    'center': tuple(entity.dxf.center[:2]),
                    'radius': entity.dxf.radius
                })
            elif entity.dxftype() == 'TEXT':
                entities_info['texts'].append({
                    'text': entity.dxf.text,
                    'position': tuple(entity.dxf.insert[:2])
                })
        
        fig, ax = plt.subplots(figsize=(12, 8))
        
        for line in entities_info['lines']:
            ax.plot([line['start'][0], line['end'][0]], 
                   [line['start'][1], line['end'][1]], 'b-', linewidth=1)
        
        for circle in entities_info['circles']:
            circle_patch = Circle(circle['center'], circle['radius'], 
                                fill=False, edgecolor='red', linewidth=1)
            ax.add_patch(circle_patch)
        
        for text in entities_info['texts']:
            ax.text(text['position'][0], text['position'][1], text['text'], 
                   fontsize=8, ha='left')
        
        ax.set_aspect('equal')
        ax.grid(True, alpha=0.3)
        ax.set_title(f"DXF Drawing: {dxf_file.name}")
        
        buffer = io.BytesIO()
        plt.savefig(buffer, format='PNG', dpi=150, bbox_inches='tight')
        buffer.seek(0)
        image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        plt.close()
        
        os.unlink(temp_file_path)
        
        metadata = {
            'file_type': 'DXF',
            'total_entities': len(list(msp)),
            'lines_count': len(entities_info['lines']),
            'circles_count': len(entities_info['circles']),
            'texts_count': len(entities_info['texts']),
            'layers': [layer.dxf.name for layer in doc.layers],
            'drawing_units': doc.header.get('$INSUNITS', 'Unknown'),
            'entities_detail': entities_info
        }
        
        return image_base64, metadata
        
    except Exception as e:
        logger.error(f"DXFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None, {"error": f"DXFå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"}

def process_stl_file(stl_file):
    """STLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦è¤‡æ•°è§’åº¦ã®ç”»åƒã‚’ç”Ÿæˆ"""
    if not STL_SUPPORT:
        return None, {"error": "STLå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
    
    try:
        stl_file.seek(0)
        with tempfile.NamedTemporaryFile(suffix='.stl', delete=False) as temp_file:
            temp_file.write(stl_file.read())
            temp_file_path = temp_file.name
        stl_file.seek(0)
        
        mesh = trimesh.load_mesh(temp_file_path)
        
        metadata = {
            'file_type': 'STL',
            'vertices_count': len(mesh.vertices),
            'faces_count': len(mesh.faces),
            'volume': float(mesh.volume),
            'surface_area': float(mesh.area),
            'bounds': mesh.bounds.tolist(),
            'center_mass': mesh.center_mass.tolist(),
            'is_watertight': mesh.is_watertight,
            'is_valid': mesh.is_valid
        }
        
        angles = [(0, 0), (90, 0), (0, 90), (45, 45)]
        images = []
        
        for i, (azimuth, elevation) in enumerate(angles):
            fig = plt.figure(figsize=(8, 8))
            ax = fig.add_subplot(111, projection='3d')
            
            ax.plot_trisurf(mesh.vertices[:, 0], 
                           mesh.vertices[:, 1], 
                           mesh.vertices[:, 2],
                           triangles=mesh.faces, 
                           alpha=0.8, cmap='viridis')
            
            ax.set_xlabel('X')
            ax.set_ylabel('Y')
            ax.set_zlabel('Z')
            ax.set_title(f"STL Model - View {i+1} ({azimuth}Â°, {elevation}Â°)")
            ax.view_init(elev=elevation, azim=azimuth)
            
            buffer = io.BytesIO()
            plt.savefig(buffer, format='PNG', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            images.append(image_base64)
            plt.close()
        
        os.unlink(temp_file_path)
        
        return images[0], {**metadata, 'additional_views': images[1:]}
        
    except Exception as e:
        logger.error(f"STLå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None, {"error": f"STLå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"}

def process_step_file(step_file):
    """STEPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ï¼ˆCadQueryä½¿ç”¨ï¼‰"""
    if not STEP_SUPPORT:
        return None, {"error": "STEPå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆCadQueryï¼‰ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
    
    try:
        step_file.seek(0)
        with tempfile.NamedTemporaryFile(suffix='.step', delete=False) as temp_file:
            temp_file.write(step_file.read())
            temp_file_path = temp_file.name
        step_file.seek(0)
        
        result = cq.importers.importStep(temp_file_path)
        
        with tempfile.NamedTemporaryFile(suffix='.stl', delete=False) as stl_temp:
            stl_temp_path = stl_temp.name
        
        cq.exporters.export(result, stl_temp_path)
        
        with open(stl_temp_path, 'rb') as stl_temp_file:
            image_base64, metadata = process_stl_file(stl_temp_file)
        
        if metadata and 'error' not in metadata:
            metadata['file_type'] = 'STEP'
            metadata['original_format'] = 'STEP/STP'
        
        os.unlink(temp_file_path)
        os.unlink(stl_temp_path)
        
        return image_base64, metadata
        
    except Exception as e:
        logger.error(f"STEPå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None, {"error": f"STEPå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"}

def process_cad_file(cad_file, file_extension):
    """CADãƒ•ã‚¡ã‚¤ãƒ«ã‚’å½¢å¼ã«å¿œã˜ã¦å‡¦ç†"""
    file_ext = file_extension.lower()
    
    if file_ext == 'dxf':
        return process_dxf_file(cad_file)
    elif file_ext == 'stl':
        return process_stl_file(cad_file)
    elif file_ext in ['step', 'stp']:
        return process_step_file(cad_file)
    elif file_ext in ['ply', 'obj'] and STL_SUPPORT:
        return process_stl_file(cad_file)
    else:
        return None, {"error": f"æœªå¯¾å¿œã®CADå½¢å¼ã§ã™: {file_ext}"}

def extract_text_with_ocr(image_file):
    """OCRã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    if not OCR_SUPPORT:
        return ""
    
    try:
        image_file.seek(0)
        image = Image.open(image_file)
        image_file.seek(0)
        
        extracted_text = pytesseract.image_to_string(image, lang='jpn+eng')
        return extracted_text.strip() if extracted_text.strip() else ""
    except Exception as e:
        logger.error(f"OCRã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def analyze_image_with_gpt4o(image_base64, filename, cad_metadata=None, client=None):
    """GPT-4oã§ç”»åƒè§£æï¼ˆCADãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
    if client is None:
        client = get_openai_client()
        if client is None:
            return {"error": "OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
    
    try:
        if cad_metadata:
            cad_info = f"""
CADãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:
- ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {cad_metadata.get('file_type', 'Unknown')}
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°: {cad_metadata.get('total_entities', 'N/A')}
- æŠ€è¡“ä»•æ§˜: {cad_metadata}
"""
            prompt = f"""
ã“ã®æŠ€è¡“å›³é¢ãƒ»CADãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å: {filename}ï¼‰ã‚’è©³ç´°ã«åˆ†æã—ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š

{cad_info}

1. image_type: å›³é¢ã®ç¨®é¡ï¼ˆæ©Ÿæ¢°å›³é¢ã€å»ºç¯‰å›³é¢ã€å›è·¯å›³ã€çµ„ç¹”å›³ã€3Dãƒ¢ãƒ‡ãƒ«ã€ãã®ä»–ï¼‰
2. main_content: å›³é¢ã®ä¸»è¦ãªå†…å®¹ã¨æŠ€è¡“çš„èª¬æ˜ï¼ˆ300-400æ–‡å­—ï¼‰
3. technical_specifications: æŠ€è¡“ä»•æ§˜ãƒ»å¯¸æ³•ãƒ»æè³ªãªã©ã®è©³ç´°æƒ…å ±
4. detected_elements: å›³é¢å†…ã®ä¸»è¦ãªè¦ç´ ãƒ»éƒ¨å“ãƒªã‚¹ãƒˆï¼ˆæœ€å¤§15å€‹ï¼‰
5. dimensions_info: å¯¸æ³•æƒ…å ±ã‚„æ¸¬å®šå€¤ï¼ˆæ¤œå‡ºã§ãã‚‹å ´åˆï¼‰
6. annotations: æ³¨è¨˜ãƒ»æ–‡å­—æƒ…å ±ãƒ»è¨˜å·ã®å†…å®¹
7. drawing_standards: å›³é¢è¦æ ¼ãƒ»æ¨™æº–ï¼ˆJISã€ISOã€ANSIç­‰ã€è©²å½“ã™ã‚‹å ´åˆï¼‰
8. manufacturing_info: è£½é€ æƒ…å ±ãƒ»åŠ å·¥æƒ…å ±ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰
9. keywords: æŠ€è¡“æ¤œç´¢ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæœ€å¤§20å€‹ï¼‰
10. category_tags: å°‚é–€åˆ†é‡ã‚¿ã‚°ï¼ˆæ©Ÿæ¢°å·¥å­¦ã€å»ºç¯‰ã€é›»æ°—å·¥å­¦ç­‰ã€æœ€å¤§10å€‹ï¼‰
11. description_for_search: æŠ€è¡“è€…å‘ã‘æ¤œç´¢çµæœè¡¨ç¤ºç”¨èª¬æ˜ï¼ˆ100-150æ–‡å­—ï¼‰
12. related_standards: é–¢é€£ã™ã‚‹æŠ€è¡“æ¨™æº–ãƒ»è¦æ ¼ã®ææ¡ˆ

JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚æŠ€è¡“çš„ãªè¦³ç‚¹ã‹ã‚‰è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ã€‚
"""
        else:
            prompt = f"""
ã“ã®ç”»åƒï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å: {filename}ï¼‰ã‚’è©³ç´°ã«åˆ†æã—ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š

1. image_type: ç”»åƒã®ç¨®é¡ï¼ˆå†™çœŸã€æŠ€è¡“å›³é¢ã€çµ„ç¹”å›³ã€ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã€ã‚°ãƒ©ãƒ•ã€è¡¨ã€åœ°å›³ã€ãã®ä»–ï¼‰
2. main_content: ç”»åƒã®ä¸»è¦ãªå†…å®¹ã®è©³ç´°èª¬æ˜ï¼ˆ200-300æ–‡å­—ï¼‰
3. detected_elements: ç”»åƒå†…ã®ä¸»è¦ãªè¦ç´ ãƒªã‚¹ãƒˆï¼ˆæœ€å¤§10å€‹ï¼‰
4. technical_details: æŠ€è¡“çš„ãªè©³ç´°ï¼ˆå¯¸æ³•ã€è¦æ ¼ã€ä»•æ§˜ãªã©ã€è©²å½“ã™ã‚‹å ´åˆï¼‰
5. text_content: ç”»åƒå†…ã«å«ã¾ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ï¼ˆã™ã¹ã¦æ­£ç¢ºã«èª­ã¿å–ã£ã¦è¨˜è¼‰ï¼‰
6. keywords: æ¤œç´¢ã«æœ‰ç”¨ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç”»åƒå†…å®¹ï¼‹ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‹ã‚‰æœ€å¤§20å€‹ï¼‰
7. search_terms: ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‹ã‚‰æƒ³å®šã•ã‚Œã‚‹æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆæœ€å¤§15å€‹ï¼‰
8. category_tags: åˆ†é¡ã‚¿ã‚°ï¼ˆæœ€å¤§8å€‹ï¼‰
9. description_for_search: æ¤œç´¢çµæœè¡¨ç¤ºç”¨ã®ç°¡æ½”ãªèª¬æ˜ï¼ˆ80-120æ–‡å­—ï¼‰
10. metadata_suggestions: è¿½åŠ ã™ã¹ããƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ææ¡ˆ
11. related_topics: ç”»åƒãƒ»ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‹ã‚‰é–¢é€£ã—ãã†ãªãƒˆãƒ”ãƒƒã‚¯ï¼ˆæœ€å¤§10å€‹ï¼‰
12. document_type_hints: æ–‡æ›¸ç¨®åˆ¥ã®æ¨å®šï¼ˆå ±å‘Šæ›¸ã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€ä»•æ§˜æ›¸ã€æ¯”è¼ƒè¡¨ç­‰ï¼‰

ç‰¹ã«é‡è¦ï¼š
- text_contentã«ã¯ç”»åƒå†…ã®ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ç¢ºã«èª­ã¿å–ã£ã¦è¨˜è¼‰ã—ã¦ãã ã•ã„
- ãã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’åŸºã«ã€æ¤œç´¢ã§ä½¿ã‚ã‚Œãã†ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å¤šæ•°ç”Ÿæˆã—ã¦ãã ã•ã„
- å°‚é–€ç”¨èªã€å›ºæœ‰åè©ã€æ•°å€¤ã€æ—¥ä»˜ãªã©ã‚‚æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å«ã‚ã¦ãã ã•ã„

JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""

        response = client.chat.completions.create(
            model=GPT4O_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            response_format={"type": "json_object"},
            max_tokens=3000
        )
        
        result = json.loads(response.choices[0].message.content)
        
        if cad_metadata:
            result['cad_metadata'] = cad_metadata
            
        return result
        
    except Exception as e:
        logger.error(f"GPT-4oç”»åƒè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": f"ç”»åƒè§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"}

def get_embedding(text, client=None, dimensions=EMBEDDING_DIMENSIONS):
    """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆtext-embedding-3-largeæœ€é©åŒ–ï¼‰"""
    if client is None:
        client = get_openai_client()
        if client is None:
            return None
    
    try:
        if not text or not text.strip():
            return None
            
        # text-embedding-3-largeã¯8191ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§å¯¾å¿œ
        if len(text) > 30000:
            text = text[:30000]
        
        # dimensionsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¯¾å¿œï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡åŒ–ï¼‰
        params = {
            "model": EMBEDDING_MODEL,
            "input": text,
            "dimensions": dimensions
        }
            
        response = client.embeddings.create(**params)
        return response.data[0].embedding
    except Exception as e:
        logger.error(f"åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_comprehensive_search_chunk(analysis_result, user_additions):
    """â˜… ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç”¨ã®åŒ…æ‹¬çš„æ¤œç´¢ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ"""
    chunk_parts = []
    
    # åŸºæœ¬æƒ…å ±
    if analysis_result.get('image_type'):
        chunk_parts.append(f"ç”»åƒã‚¿ã‚¤ãƒ—: {analysis_result['image_type']}")
    
    if analysis_result.get('main_content'):
        chunk_parts.append(f"ä¸»è¦å†…å®¹: {analysis_result['main_content']}")
    
    # æ¤œå‡ºè¦ç´ 
    elements = analysis_result.get('detected_elements', [])
    if elements:
        chunk_parts.append(f"ä¸»è¦è¦ç´ : {', '.join(elements)}")
    
    # æŠ€è¡“è©³ç´°
    tech_details = analysis_result.get('technical_details', '')
    if tech_details:
        chunk_parts.append(f"æŠ€è¡“è©³ç´°: {tech_details}")
    
    # æŠ€è¡“ä»•æ§˜ï¼ˆCADç”¨ï¼‰
    tech_specs = analysis_result.get('technical_specifications', '')
    if tech_specs:
        chunk_parts.append(f"æŠ€è¡“ä»•æ§˜: {tech_specs}")
    
    # å¯¸æ³•æƒ…å ±
    dimensions_info = analysis_result.get('dimensions_info', '')
    if dimensions_info:
        chunk_parts.append(f"å¯¸æ³•æƒ…å ±: {dimensions_info}")
    
    # GPTãŒèª­ã¿å–ã£ãŸãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ï¼ˆé‡è¦ï¼šæ¤œç´¢å¯¾è±¡ï¼‰
    text_content = analysis_result.get('text_content', '')
    if text_content and text_content.strip():
        chunk_parts.append(f"ç”»åƒå†…ãƒ†ã‚­ã‚¹ãƒˆ: {text_content}")
    
    # æ³¨è¨˜ãƒ»è¨˜å·
    annotations = analysis_result.get('annotations', '')
    if annotations:
        chunk_parts.append(f"æ³¨è¨˜ãƒ»è¨˜å·: {annotations}")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ æƒ…å ±
    if user_additions.get('additional_description'):
        chunk_parts.append(f"è£œè¶³èª¬æ˜: {user_additions['additional_description']}")
    
    if user_additions.get('purpose'):
        chunk_parts.append(f"ç”¨é€”ãƒ»ç›®çš„: {user_additions['purpose']}")
    
    if user_additions.get('context'):
        chunk_parts.append(f"æ–‡è„ˆãƒ»èƒŒæ™¯: {user_additions['context']}")
    
    if user_additions.get('related_documents'):
        chunk_parts.append(f"é–¢é€£æ–‡æ›¸: {user_additions['related_documents']}")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±åˆ
    keywords = analysis_result.get('keywords', [])
    user_keywords = user_additions.get('additional_keywords', [])
    search_terms = analysis_result.get('search_terms', [])
    all_keywords = keywords + user_keywords + search_terms
    if all_keywords:
        chunk_parts.append(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(set(all_keywords))}")  # é‡è¤‡é™¤å»
    
    # é–¢é€£ãƒˆãƒ”ãƒƒã‚¯
    related_topics = analysis_result.get('related_topics', [])
    if related_topics:
        chunk_parts.append(f"é–¢é€£ãƒˆãƒ”ãƒƒã‚¯: {', '.join(related_topics)}")
    
    return "\n".join(chunk_parts)

def create_structured_metadata(analysis_result, user_additions, filename):
    """â˜… æ§‹é€ åŒ–ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆæ¤œç´¢çµæœè¡¨ç¤ºç”¨ï¼‰"""
    return {
        # åŸºæœ¬æƒ…å ±
        "filename": filename,
        "image_type": analysis_result.get('image_type', ''),
        "category": user_additions.get('category', ''),
        "importance": user_additions.get('importance', 'ä¸­'),
        
        # è¡¨ç¤ºç”¨èª¬æ˜
        "title": user_additions.get('title', analysis_result.get('main_content', '')[:50] + '...'),
        "description_for_search": analysis_result.get('description_for_search', ''),
        "main_content": analysis_result.get('main_content', ''),
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
        "purpose": user_additions.get('purpose', ''),
        "context": user_additions.get('context', ''),
        "related_documents": user_additions.get('related_documents', ''),
        
        # åˆ†é¡ãƒ»ã‚¿ã‚°
        "keywords": analysis_result.get('keywords', []) + user_additions.get('additional_keywords', []),
        "search_terms": analysis_result.get('search_terms', []),
        "category_tags": analysis_result.get('category_tags', []),
        "related_topics": analysis_result.get('related_topics', []),
        
        # æŠ€è¡“æƒ…å ±
        "technical_details": analysis_result.get('technical_details', ''),
        "technical_specifications": analysis_result.get('technical_specifications', ''),
        "dimensions_info": analysis_result.get('dimensions_info', ''),
        "drawing_standards": analysis_result.get('drawing_standards', ''),
        "manufacturing_info": analysis_result.get('manufacturing_info', ''),
        
        # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
        "text_content": analysis_result.get('text_content', ''),
        "annotations": analysis_result.get('annotations', ''),
        
        # è¦ç´ 
        "detected_elements": analysis_result.get('detected_elements', []),
        
        # CADãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        "cad_metadata": analysis_result.get('cad_metadata', {})
    }

def save_unified_knowledge_item(image_id, analysis_result, user_additions, embedding, filename, image_base64=None):
    """â˜… çµ±ä¸€ãƒŠãƒ¬ãƒƒã‚¸ã‚¢ã‚¤ãƒ†ãƒ ã¨ã—ã¦ä¿å­˜ï¼ˆRAGã‚·ã‚¹ãƒ†ãƒ äº’æ›æ§‹é€ ï¼‰"""
    try:
        # ãƒãƒ£ãƒ³ã‚¯ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        search_chunk = create_comprehensive_search_chunk(analysis_result, user_additions)
        structured_metadata = create_structured_metadata(analysis_result, user_additions, filename)
        
        # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        kb_name = "multimodal_knowledge_base"
        kb_dir = DATA_DIR / kb_name
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆï¼ˆæ—¢å­˜RAGã‚·ã‚¹ãƒ†ãƒ äº’æ›ï¼‰
        chunks_dir = kb_dir / "chunks"
        embeddings_dir = kb_dir / "embeddings"
        metadata_dir = kb_dir / "metadata"
        images_dir = kb_dir / "images"
        files_dir = kb_dir / "files"
        
        for dir_path in [chunks_dir, embeddings_dir, metadata_dir, images_dir, files_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯ç”Ÿæˆï¼ˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ï¼‰
        file_extension = filename.split('.')[-1].lower() if '.' in filename else ''
        original_file_path = files_dir / f"{image_id}.{file_extension}"
        file_link = f"./files/{image_id}.{file_extension}"  # ç›¸å¯¾ãƒ‘ã‚¹
        
        # 1. ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆchunks/ï¼‰
        chunk_data = {
            "id": image_id,
            "content": search_chunk,
            "filename": filename,
            "created_at": datetime.now().isoformat(),
            "type": "image_knowledge",
            "file_link": file_link,  # â˜… ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯è¿½åŠ 
            "chunk_metadata": {
                "keywords": structured_metadata.get('keywords', []),
                "search_terms": structured_metadata.get('search_terms', []),
                "category": structured_metadata.get('category', ''),
                "importance": structured_metadata.get('importance', 'ä¸­')
            }
        }
        
        chunk_file_path = chunks_dir / f"{image_id}.json"
        with open(chunk_file_path, 'w', encoding='utf-8') as f:
            json.dump(chunk_data, f, ensure_ascii=False, indent=2)
        
        # 2. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆembeddings/ï¼‰
        embedding_data = {
            "id": image_id,
            "vector": embedding,
            "model": EMBEDDING_MODEL,
            "dimensions": len(embedding) if embedding else 0,
            "created_at": datetime.now().isoformat(),
            "file_link": file_link  # â˜… ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯è¿½åŠ 
        }
        
        embedding_file_path = embeddings_dir / f"{image_id}.json"
        with open(embedding_file_path, 'w', encoding='utf-8') as f:
            json.dump(embedding_data, f, ensure_ascii=False, indent=2)
        
        # 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆmetadata/ï¼‰
        full_metadata = {
            "id": image_id,
            "filename": filename,
            "content_type": "image/jpeg",
            "created_at": datetime.now().isoformat(),
            "file_link": file_link,  # â˜… ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯è¿½åŠ 
            
            # æ¤œç´¢çµæœè¡¨ç¤ºç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            "display_metadata": structured_metadata,
            
            # AIè§£æã®è©³ç´°ãƒ‡ãƒ¼ã‚¿
            "analysis_data": {
                "gpt_analysis": analysis_result,
                "cad_metadata": analysis_result.get('cad_metadata', {}),
                "user_additions": user_additions
            },
            
            # çµ±è¨ˆæƒ…å ±
            "stats": {
                "keywords_count": len(structured_metadata.get('keywords', [])),
                "search_terms_count": len(structured_metadata.get('search_terms', [])),
                "detected_elements_count": len(structured_metadata.get('detected_elements', [])),
                "chunk_length": len(search_chunk),
                "vector_dimensions": len(embedding) if embedding else 0
            }
        }
        
        metadata_file_path = metadata_dir / f"{image_id}.json"
        with open(metadata_file_path, 'w', encoding='utf-8') as f:
            json.dump(full_metadata, f, ensure_ascii=False, indent=2)
        
        # 4. ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆimages/ï¼‰
        if image_base64:
            try:
                image_bytes = base64.b64decode(image_base64)
                image_file_path = images_dir / f"{image_id}.jpg"
                with open(image_file_path, 'wb') as f:
                    f.write(image_bytes)
            except Exception as e:
                logger.warning(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 5. å…ƒãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ï¼ˆfiles/ï¼‰- å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆ¥é€”ã‚³ãƒ”ãƒ¼ãŒå¿…è¦
        file_info = {
            "id": image_id,
            "original_filename": filename,
            "file_extension": file_extension,
            "file_path": str(original_file_path),
            "file_link": file_link,
            "created_at": datetime.now().isoformat(),
            "note": "å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ‰‹å‹•ã§ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„"
        }
        
        file_info_path = files_dir / f"{image_id}_info.json"
        with open(file_info_path, 'w', encoding='utf-8') as f:
            json.dump(file_info, f, ensure_ascii=False, indent=2)
        
        # 6. ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®æƒ…å ±æ›´æ–°
        kb_metadata_path = kb_dir / "kb_metadata.json"
        try:
            if kb_metadata_path.exists():
                with open(kb_metadata_path, 'r', encoding='utf-8') as f:
                    kb_metadata = json.load(f)
            else:
                kb_metadata = {
                    "kb_name": kb_name,
                    "created_at": datetime.now().isoformat(),
                    "total_items": 0,
                    "item_types": {"image": 0, "text_chunk": 0}
                }
            
            # çµ±è¨ˆæ›´æ–°
            kb_metadata["total_items"] += 1
            kb_metadata["item_types"]["image"] += 1
            kb_metadata["last_updated"] = datetime.now().isoformat()
            
            with open(kb_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(kb_metadata, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.warning(f"KB ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        
        # çµ±åˆç”¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        unified_item = {
            "id": image_id,
            "type": "image",
            "filename": filename,
            "file_link": file_link,
            "chunk_path": str(chunk_file_path),
            "embedding_path": str(embedding_file_path),
            "metadata_path": str(metadata_file_path),
            "stats": full_metadata["stats"]
        }
        
        return True, unified_item
        
    except Exception as e:
        logger.error(f"ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False, None

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# ãƒ¡ã‚¤ãƒ³UI
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

st.title("ğŸ–¼ï¸ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒŠãƒ¬ãƒƒã‚¸æ§‹ç¯‰ãƒ„ãƒ¼ãƒ«")
st.markdown("ç”»åƒãƒ»å›³é¢ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®æ”¹è‰¯ç‰ˆãƒ„ãƒ¼ãƒ«ã§ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("âš™ï¸ è¨­å®š")
show_debug = st.sidebar.checkbox("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º", value=False)
embedding_dims = st.sidebar.selectbox(
    "åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°",
    [1536, 3072],
    index=0,
    help="1536: ã‚³ã‚¹ãƒˆåŠ¹ç‡é‡è¦–ã€3072: ç²¾åº¦é‡è¦–"
)

# ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–
tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "âœï¸ å†…å®¹ç·¨é›†ãƒ»ãƒŠãƒ¬ãƒƒã‚¸åŒ–", "ğŸ“Š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†"])

with tab1:
    st.header("ç”»åƒãƒ»å›³é¢ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®èª¬æ˜
    with st.expander("ğŸ“‹ å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼"):
        st.markdown(f"""
        **ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«**: {', '.join(SUPPORTED_IMAGE_TYPES)}
        **æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«**: {', '.join(SUPPORTED_DOCUMENT_TYPES) if PDF_SUPPORT else 'PDFå‡¦ç†ç„¡åŠ¹'}
        **CADãƒ•ã‚¡ã‚¤ãƒ«**: {', '.join(SUPPORTED_CAD_TYPES)}
        
        ### ğŸ“ CADå½¢å¼å¯¾å¿œçŠ¶æ³
        - **DXF** âœ… - AutoCADå›³é¢äº¤æ›å½¢å¼ {('(å¯¾å¿œæ¸ˆã¿)' if DXF_SUPPORT else '(è¦ezdxf)')}
        - **STL** âœ… - 3Dãƒ—ãƒªãƒ³ã‚¿ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ« {('(å¯¾å¿œæ¸ˆã¿)' if STL_SUPPORT else '(è¦trimesh)')}
        - **STEP/STP** ğŸ”¶ - 3D CADæ¨™æº–äº¤æ›å½¢å¼ {('(å¯¾å¿œæ¸ˆã¿)' if STEP_SUPPORT else '(è¦cadquery)')}
        - **PLY/OBJ** ğŸ”¶ - 3Dãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ« {('(å¯¾å¿œæ¸ˆã¿)' if STL_SUPPORT else '(è¦trimesh)')}
        """)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_files = st.file_uploader(
        "ç”»åƒãƒ»CADãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=SUPPORTED_IMAGE_TYPES + SUPPORTED_DOCUMENT_TYPES + SUPPORTED_CAD_TYPES,
        accept_multiple_files=True,
        help="è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®åŒæ™‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¯èƒ½ã§ã™ã€‚CADãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«ç”»åƒã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚"
    )
    
    if uploaded_files:
        st.success(f"{len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
        
        if st.button("ğŸ” AIè§£æã‚’é–‹å§‹", type="primary"):
            client = get_openai_client()
            if not client:
                st.error("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æ¥ç¶šã§ãã¾ã›ã‚“")
            else:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for i, uploaded_file in enumerate(uploaded_files):
                    status_text.text(f"å‡¦ç†ä¸­: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
                    
                    file_extension = uploaded_file.name.split('.')[-1].lower()
                    is_cad_file = file_extension in SUPPORTED_CAD_TYPES
                    
                    image_base64 = None
                    cad_metadata = None
                    
                    if is_cad_file:
                        with st.spinner(f"CADãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­: {uploaded_file.name}"):
                            image_base64, cad_metadata = process_cad_file(uploaded_file, file_extension)
                            if image_base64 is None:
                                st.error(f"CADãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {uploaded_file.name} - {cad_metadata.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
                                continue
                    else:
                        image_base64 = encode_image_to_base64(uploaded_file)
                        if not image_base64:
                            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {uploaded_file.name}")
                            continue
                    
                    # GPT-4oè§£æ
                    with st.spinner(f"GPT-4.1ã§è§£æä¸­: {uploaded_file.name}"):
                        analysis = analyze_image_with_gpt4o(image_base64, uploaded_file.name, cad_metadata, client)
                    
                    if "error" not in analysis:
                        image_id = str(uuid.uuid4())
                        st.session_state.processed_images[image_id] = {
                            'filename': uploaded_file.name,
                            'file_extension': file_extension,
                            'is_cad_file': is_cad_file,
                            'image_base64': image_base64,
                            'analysis': analysis,
                            'cad_metadata': cad_metadata,
                            'user_additions': {},
                            'is_finalized': False
                        }
                        
                        file_type_display = "CADãƒ•ã‚¡ã‚¤ãƒ«" if is_cad_file else "ç”»åƒ"
                        st.success(f"âœ… {uploaded_file.name} ({file_type_display}) ã®è§£æå®Œäº†")
                    else:
                        st.error(f"âŒ {uploaded_file.name} ã®è§£æå¤±æ•—: {analysis.get('error')}")
                    
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                status_text.text("å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")

with tab2:
    st.header("å†…å®¹ç·¨é›†ãƒ»ãƒŠãƒ¬ãƒƒã‚¸åŒ–")
    
    if not st.session_state.processed_images:
        st.info("ã€Œç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚¿ãƒ–ã§ç”»åƒã‚’å‡¦ç†ã—ã¦ãã ã•ã„")
    else:
        # ç”»åƒé¸æŠ
        image_options = {f"{data['filename']} (ID: {img_id[:8]}...)": img_id 
                        for img_id, data in st.session_state.processed_images.items()}
        
        selected_display = st.selectbox(
            "ç·¨é›†ã™ã‚‹ç”»åƒã‚’é¸æŠ",
            list(image_options.keys()),
            index=0
        )
        
        if selected_display:
            selected_id = image_options[selected_display]
            image_data = st.session_state.processed_images[selected_id]
            
            # â˜…â˜…â˜… 3åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼šç”»åƒã€AIãƒ‡ãƒ¼ã‚¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç·¨é›† â˜…â˜…â˜…
            col1, col2, col3 = st.columns([1, 1, 1])
            
            with col1:
                st.subheader("ğŸ–¼ï¸ ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                
                try:
                    image_bytes = base64.b64decode(image_data['image_base64'])
                    image = Image.open(io.BytesIO(image_bytes))
                    st.image(image, caption=image_data['filename'], use_container_width=True)
                except Exception as e:
                    st.error(f"ç”»åƒè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
                if image_data.get('is_cad_file', False):
                    st.info(f"ğŸ”§ CADãƒ•ã‚¡ã‚¤ãƒ«: {image_data['file_extension'].upper()}")
                    
                    if image_data.get('cad_metadata'):
                        cad_meta = image_data['cad_metadata']
                        with st.expander("ğŸ“ CADæŠ€è¡“æƒ…å ±"):
                            if cad_meta.get('file_type'):
                                st.write(f"**å½¢å¼**: {cad_meta['file_type']}")
                            if cad_meta.get('total_entities'):
                                st.write(f"**ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°**: {cad_meta['total_entities']}")
                            if cad_meta.get('vertices_count'):
                                st.write(f"**é ‚ç‚¹æ•°**: {cad_meta['vertices_count']}")
                            if cad_meta.get('volume'):
                                st.write(f"**ä½“ç©**: {cad_meta['volume']:.3f}")
            
            with col2:
                st.subheader("ğŸ¤– AIè§£æçµæœ")
                analysis = image_data['analysis']
                
                st.write(f"**ç”»åƒã‚¿ã‚¤ãƒ—**: {analysis.get('image_type', 'N/A')}")
                
                with st.expander("ğŸ“ AIæŠ½å‡ºå†…å®¹ï¼ˆå‚è€ƒï¼‰", expanded=False):
                    if analysis.get('main_content'):
                        st.write(f"**ä¸»è¦å†…å®¹**: {analysis['main_content']}")
                    
                    if analysis.get('detected_elements'):
                        st.write("**æ¤œå‡ºè¦ç´ **:")
                        for element in analysis['detected_elements'][:5]:  # ä¸Šä½5ã¤ã®ã¿è¡¨ç¤º
                            st.write(f"- {element}")
                    
                    if analysis.get('text_content'):
                        st.write(f"**ç”»åƒå†…ãƒ†ã‚­ã‚¹ãƒˆ**: {analysis['text_content'][:200]}...")
                    
                    if analysis.get('keywords'):
                        st.write(f"**AIç”Ÿæˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(analysis['keywords'][:8])}...")
                    
                    if analysis.get('technical_details'):
                        st.write(f"**æŠ€è¡“è©³ç´°**: {analysis['technical_details']}")
                
                # â˜…â˜…â˜… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ â˜…â˜…â˜…
                st.subheader("ğŸ” ãƒŠãƒ¬ãƒƒã‚¸ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                
                if st.button("ğŸ“„ æœ€æ–°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ"):
                    user_additions = image_data.get('user_additions', {})
                    
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
                    preview_chunk = create_comprehensive_search_chunk(analysis, user_additions)
                    preview_metadata = create_structured_metadata(analysis, user_additions, image_data['filename'])
                    
                    st.markdown("**ğŸ’¾ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚Œã‚‹æ¤œç´¢ãƒãƒ£ãƒ³ã‚¯:**")
                    with st.container():
                        st.text_area("", preview_chunk, height=150, disabled=True, key="preview_chunk")
                        st.caption(f"æ–‡å­—æ•°: {len(preview_chunk)}")
                    
                    st.markdown("**ğŸ“Š æ§‹é€ åŒ–ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¤œç´¢çµæœè¡¨ç¤ºç”¨ï¼‰:**")
                    with st.expander("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è©³ç´°", expanded=False):
                        st.json(preview_metadata)
            
            with col3:
                st.subheader("âœï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ æƒ…å ±")
                
                user_additions = image_data.get('user_additions', {})
                
                # ã‚¿ã‚¤ãƒˆãƒ«
                title = st.text_input(
                    "ğŸ“ ã‚¿ã‚¤ãƒˆãƒ«",
                    value=user_additions.get('title', ''),
                    help="æ¤œç´¢çµæœã«è¡¨ç¤ºã•ã‚Œã‚‹ã‚¿ã‚¤ãƒˆãƒ«"
                )
                
                # è£œè¶³èª¬æ˜
                additional_description = st.text_area(
                    "ğŸ“„ è£œè¶³èª¬æ˜",
                    value=user_additions.get('additional_description', ''),
                    help="AIã®è§£æã«è¿½åŠ ã—ãŸã„è©³ç´°ãªèª¬æ˜ï¼ˆé‡è¦ï¼šæ¤œç´¢å¯¾è±¡ã«ãªã‚Šã¾ã™ï¼‰",
                    height=100
                )
                
                # ç”¨é€”ãƒ»ç›®çš„
                purpose = st.text_input(
                    "ğŸ¯ ç”¨é€”ãƒ»ç›®çš„",
                    value=user_additions.get('purpose', ''),
                    help="ã“ã®ç”»åƒã®ç”¨é€”ã‚„ç›®çš„"
                )
                
                # æ–‡è„ˆãƒ»èƒŒæ™¯
                context = st.text_area(
                    "ğŸ“– æ–‡è„ˆãƒ»èƒŒæ™¯",
                    value=user_additions.get('context', ''),
                    help="ã“ã®ç”»åƒã®èƒŒæ™¯æƒ…å ±ã‚„æ–‡è„ˆ",
                    height=80
                )
                
                # é–¢é€£æ–‡æ›¸
                related_documents = st.text_input(
                    "ğŸ“ é–¢é€£æ–‡æ›¸",
                    value=user_additions.get('related_documents', ''),
                    help="é–¢é€£ã™ã‚‹æ–‡æ›¸ã‚„ãƒ•ã‚¡ã‚¤ãƒ«å"
                )
                
                # è¿½åŠ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                additional_keywords_str = st.text_input(
                    "ğŸ·ï¸ è¿½åŠ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
                    value=', '.join(user_additions.get('additional_keywords', [])),
                    help="æ¤œç´¢ç”¨ã®è¿½åŠ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡è¦ï¼šæ¤œç´¢æ€§èƒ½å‘ä¸Šï¼‰"
                )
                additional_keywords = [kw.strip() for kw in additional_keywords_str.split(',') if kw.strip()]
                
                # ã‚«ãƒ†ã‚´ãƒªã¨é‡è¦åº¦
                col3_1, col3_2 = st.columns(2)
                with col3_1:
                    category_options = ["æŠ€è¡“æ–‡æ›¸", "çµ„ç¹”å›³", "ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ", "ãƒ‡ãƒ¼ã‚¿å›³è¡¨", "å†™çœŸ", "åœ°å›³", "ãã®ä»–"]
                    selected_category = st.selectbox(
                        "ğŸ—‚ï¸ ã‚«ãƒ†ã‚´ãƒª",
                        category_options,
                        index=category_options.index(user_additions.get('category', 'æŠ€è¡“æ–‡æ›¸')) 
                              if user_additions.get('category') in category_options else 0
                    )
                
                with col3_2:
                    importance = st.select_slider(
                        "â­ é‡è¦åº¦",
                        options=["ä½", "ä¸­", "é«˜", "æœ€é‡è¦"],
                        value=user_additions.get('importance', 'ä¸­')
                    )
                
                # æƒ…å ±æ›´æ–°
                if st.button("ğŸ’¾ æƒ…å ±ã‚’æ›´æ–°", type="secondary"):
                    st.session_state.processed_images[selected_id]['user_additions'] = {
                        'title': title,
                        'additional_description': additional_description,
                        'purpose': purpose,
                        'context': context,
                        'related_documents': related_documents,
                        'additional_keywords': additional_keywords,
                        'category': selected_category,
                        'importance': importance
                    }
                    st.success("âœ… æƒ…å ±ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ")
                    st.rerun()
                
                st.markdown("---")
                
                # â˜…â˜…â˜… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç™»éŒ² â˜…â˜…â˜…
                st.subheader("ğŸš€ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç™»éŒ²")
                
                if not image_data.get('is_finalized', False):
                    if st.button("âœ… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²", type="primary"):
                        with st.spinner("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç™»éŒ²ä¸­..."):
                            client = get_openai_client()
                            if client:
                                # æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
                                current_user_additions = st.session_state.processed_images[selected_id]['user_additions']
                                
                                # ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
                                search_chunk = create_comprehensive_search_chunk(analysis, current_user_additions)
                                
                                # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
                                embedding = get_embedding(search_chunk, client, dimensions=embedding_dims)
                                
                                if embedding:
                                    # çµ±ä¸€ãƒŠãƒ¬ãƒƒã‚¸ã‚¢ã‚¤ãƒ†ãƒ ã¨ã—ã¦ä¿å­˜
                                    success, saved_item = save_unified_knowledge_item(
                                        selected_id,
                                        analysis,
                                        current_user_additions,
                                        embedding,
                                        image_data['filename'],
                                        image_data['image_base64']
                                    )
                                    
                                    if success:
                                        st.session_state.processed_images[selected_id]['is_finalized'] = True
                                        st.success("âœ… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²å®Œäº†ï¼")
                                        
                                        # ç™»éŒ²çµæœè¡¨ç¤ºï¼ˆåˆ†é›¢æ§‹é€ å¯¾å¿œï¼‰
                                        with st.expander("ğŸ“Š ç™»éŒ²ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢å­˜RAGã‚·ã‚¹ãƒ†ãƒ äº’æ›ï¼‰", expanded=True):
                                            st.write(f"**ID**: {saved_item['id']}")
                                            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯**: {saved_item['file_link']}")
                                            st.write(f"**ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒæ•°**: {saved_item['stats']['vector_dimensions']}")
                                            st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°**: {saved_item['stats']['keywords_count']}")
                                            st.write(f"**ãƒãƒ£ãƒ³ã‚¯æ–‡å­—æ•°**: {saved_item['stats']['chunk_length']}")
                                            
                                            st.markdown("**ğŸ“ ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«:**")
                                            st.code(f"""
chunks/{saved_item['id']}.json      # æ¤œç´¢ç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯
embeddings/{saved_item['id']}.json  # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿
metadata/{saved_item['id']}.json    # ãƒ¡ã‚¿æƒ…å ±
images/{saved_item['id']}.jpg       # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
files/{saved_item['id']}_info.json  # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
                                            """)
                                        
                                        if show_debug:
                                            with st.expander("ğŸ”§ ãƒ‡ãƒãƒƒã‚°: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒãƒ£ãƒ³ã‚¯"):
                                                st.text_area("", search_chunk, height=150, disabled=True)
                                    else:
                                        st.error("âŒ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç™»éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                                else:
                                    st.error("âŒ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                            else:
                                st.error("âŒ OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æ¥ç¶šã§ãã¾ã›ã‚“")
                else:
                    st.success("âœ… ã“ã®ç”»åƒã¯æ—¢ã«ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç™»éŒ²æ¸ˆã¿ã§ã™")
                    
                    if st.button("ğŸ”„ å†ç™»éŒ²ï¼ˆæƒ…å ±æ›´æ–°ï¼‰", help="æƒ…å ±ã‚’æ›´æ–°ã—ã¦å†åº¦ç™»éŒ²ã—ã¾ã™"):
                        st.session_state.processed_images[selected_id]['is_finalized'] = False
                        st.rerun()

with tab3:
    st.header("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†")
    
    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹é¸æŠ
    kb_name = st.selectbox(
        "ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹é¸æŠ",
        ["multimodal_knowledge_base"],  # å°†æ¥è¤‡æ•°KBå¯¾å¿œå¯èƒ½
        index=0
    )
    
    # æ—¢å­˜RAGã‚·ã‚¹ãƒ†ãƒ äº’æ›ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
    kb_dir = DATA_DIR / kb_name
    chunks_dir = kb_dir / "chunks"
    embeddings_dir = kb_dir / "embeddings"
    metadata_dir = kb_dir / "metadata"
    images_dir = kb_dir / "images"
    files_dir = kb_dir / "files"
    
    if metadata_dir.exists():
        metadata_files = list(metadata_dir.glob("*.json"))
        if metadata_files:
            # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±è¨ˆè¡¨ç¤º
            kb_metadata_path = kb_dir / "kb_metadata.json"
            if kb_metadata_path.exists():
                try:
                    with open(kb_metadata_path, 'r', encoding='utf-8') as f:
                        kb_info = json.load(f)
                    
                    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
                    with col_stat1:
                        st.metric("ğŸ“š ç·ã‚¢ã‚¤ãƒ†ãƒ æ•°", kb_info.get('total_items', len(metadata_files)))
                    with col_stat2:
                        st.metric("ğŸ–¼ï¸ ç”»åƒ", kb_info.get('item_types', {}).get('image', len(metadata_files)))
                    with col_stat3:
                        st.metric("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆ", kb_info.get('item_types', {}).get('text_chunk', 0))
                    with col_stat4:
                        st.metric("ğŸ”„ æœ€çµ‚æ›´æ–°", kb_info.get('last_updated', '')[:10] if kb_info.get('last_updated') else 'N/A')
                except:
                    st.info(f"ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç™»éŒ²ãƒ‡ãƒ¼ã‚¿: {len(metadata_files)}ä»¶")
            else:
                st.info(f"ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç™»éŒ²ãƒ‡ãƒ¼ã‚¿: {len(metadata_files)}ä»¶")
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ è¡¨ç¤º
            with st.expander("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ï¼ˆæ—¢å­˜RAGã‚·ã‚¹ãƒ†ãƒ äº’æ›ï¼‰", expanded=False):
                st.code(f"""
ğŸ“ {kb_name}/
â”œâ”€â”€ ğŸ“„ chunks/      ({len(list(chunks_dir.glob('*.json')) if chunks_dir.exists() else [])}ä»¶)
â”œâ”€â”€ ğŸ”¢ embeddings/  ({len(list(embeddings_dir.glob('*.json')) if embeddings_dir.exists() else [])}ä»¶)
â”œâ”€â”€ ğŸ“Š metadata/    ({len(list(metadata_dir.glob('*.json')) if metadata_dir.exists() else [])}ä»¶)
â”œâ”€â”€ ğŸ–¼ï¸ images/      ({len(list(images_dir.glob('*.*')) if images_dir.exists() else [])}ä»¶)
â”œâ”€â”€ ğŸ“ files/       ({len(list(files_dir.glob('*.json')) if files_dir.exists() else [])}ä»¶)
â””â”€â”€ ğŸ“‹ kb_metadata.json
                """)
            
            # ãƒ‡ãƒ¼ã‚¿ä¸€è¦§è¡¨ç¤º
            data_list = []
            for metadata_file in metadata_files:
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    display_meta = data.get('display_metadata', {})
                    stats = data.get('stats', {})
                    
                    data_list.append({
                        'ID': data['id'][:8] + '...',
                        'ãƒ•ã‚¡ã‚¤ãƒ«å': data.get('filename', 'N/A'),
                        'ã‚¿ã‚¤ãƒˆãƒ«': display_meta.get('title', 'N/A')[:30] + '...' if len(display_meta.get('title', '')) > 30 else display_meta.get('title', 'N/A'),
                        'ç”»åƒã‚¿ã‚¤ãƒ—': display_meta.get('image_type', 'N/A'),
                        'ã‚«ãƒ†ã‚´ãƒª': display_meta.get('category', 'N/A'),
                        'é‡è¦åº¦': display_meta.get('importance', 'N/A'),
                        'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°': stats.get('keywords_count', 0),
                        'ãƒãƒ£ãƒ³ã‚¯æ–‡å­—æ•°': stats.get('chunk_length', 0),
                        'ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ': stats.get('vector_dimensions', 0),
                        'ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯': data.get('file_link', 'N/A'),
                        'ä½œæˆæ—¥æ™‚': data.get('created_at', '')[:19]
                    })
                except Exception as e:
                    logger.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {metadata_file}: {e}")
            
            if data_list:
                df = pd.DataFrame(data_list)
                st.dataframe(df, use_container_width=True)
                
                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
                if st.button("ğŸ“¥ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ’¾ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv,
                        file_name=f"{kb_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                # â˜…â˜…â˜… æ”¹è‰¯ç‰ˆãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ï¼ˆåˆ†é›¢æ§‹é€ å¯¾å¿œï¼‰ â˜…â˜…â˜…
                st.subheader("ğŸ” ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢")
                
                col_search1, col_search2 = st.columns([3, 1])
                with col_search1:
                    search_query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›", placeholder="ä¾‹: WEBç‰ˆ æ¯”è¼ƒé …ç›®ã€æŠ€è¡“ä»•æ§˜ã€çµ„ç¹”å›³")
                
                with col_search2:
                    search_top_k = st.selectbox("è¡¨ç¤ºä»¶æ•°", [5, 10, 15, 20], index=1)
                
                if search_query and st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary"):
                    client = get_openai_client()
                    if client:
                        with st.spinner("æ¤œç´¢ä¸­..."):
                            # ã‚¯ã‚¨ãƒªã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
                            query_embedding = get_embedding(search_query, client, dimensions=embedding_dims)
                            
                            if query_embedding:
                                # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆåˆ†é›¢æ§‹é€ å¯¾å¿œï¼‰
                                similarities = []
                                
                                for metadata_file in metadata_files:
                                    try:
                                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                                        with open(metadata_file, 'r', encoding='utf-8') as f:
                                            metadata = json.load(f)
                                        
                                        item_id = metadata['id']
                                        
                                        # å¯¾å¿œã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
                                        embedding_file = embeddings_dir / f"{item_id}.json"
                                        if embedding_file.exists():
                                            with open(embedding_file, 'r', encoding='utf-8') as f:
                                                embedding_data = json.load(f)
                                            
                                            doc_embedding = embedding_data.get('vector')
                                            if doc_embedding and len(doc_embedding) == len(query_embedding):
                                                # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
                                                similarity = np.dot(query_embedding, doc_embedding) / (
                                                    np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
                                                )
                                                
                                                # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿ï¼ˆæ¤œç´¢çµæœè¡¨ç¤ºç”¨ï¼‰
                                                chunk_file = chunks_dir / f"{item_id}.json"
                                                chunk_data = {}
                                                if chunk_file.exists():
                                                    with open(chunk_file, 'r', encoding='utf-8') as f:
                                                        chunk_data = json.load(f)
                                                
                                                similarities.append({
                                                    'metadata': metadata,
                                                    'chunk_data': chunk_data,
                                                    'embedding_data': embedding_data,
                                                    'similarity': similarity
                                                })
                                    except Exception as e:
                                        logger.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼ {metadata_file}: {e}")
                                
                                # é¡ä¼¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
                                similarities.sort(key=lambda x: x['similarity'], reverse=True)
                                
                                # æ¤œç´¢çµæœè¡¨ç¤º
                                st.write(f"**ğŸ¯ æ¤œç´¢çµæœï¼ˆä¸Šä½{min(search_top_k, len(similarities))}ä»¶ï¼‰**")
                                
                                if similarities:
                                    for i, result in enumerate(similarities[:search_top_k]):
                                        metadata = result['metadata']
                                        display_meta = metadata.get('display_metadata', {})
                                        stats = metadata.get('stats', {})
                                        chunk_data = result.get('chunk_data', {})
                                        
                                        with st.expander(f"{i+1}. {display_meta.get('title', metadata.get('filename', 'N/A'))} (é¡ä¼¼åº¦: {result['similarity']:.3f})"):
                                            # 4åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
                                            result_col1, result_col2, result_col3, result_col4 = st.columns([1, 1, 1, 1])
                                            
                                            with result_col1:
                                                st.markdown("**ğŸ“„ åŸºæœ¬æƒ…å ±**")
                                                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {metadata.get('filename', 'N/A')}")
                                                st.write(f"**ã‚¿ã‚¤ãƒ—**: {display_meta.get('image_type', 'N/A')}")
                                                st.write(f"**ã‚«ãƒ†ã‚´ãƒª**: {display_meta.get('category', 'N/A')}")
                                                st.write(f"**é‡è¦åº¦**: {display_meta.get('importance', 'N/A')}")
                                                
                                                # â˜… ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯è¡¨ç¤º
                                                file_link = metadata.get('file_link', '')
                                                if file_link:
                                                    st.write(f"**ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯**: `{file_link}`")
                                            
                                            with result_col2:
                                                st.markdown("**ğŸ“Š çµ±è¨ˆãƒ»ã‚¹ã‚³ã‚¢**")
                                                st.metric("é¡ä¼¼åº¦", f"{result['similarity']:.3f}")
                                                st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°**: {stats.get('keywords_count', 0)}")
                                                st.write(f"**ãƒãƒ£ãƒ³ã‚¯æ–‡å­—æ•°**: {stats.get('chunk_length', 0)}")
                                                st.write(f"**ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ**: {stats.get('vector_dimensions', 0)}")
                                                st.write(f"**ä½œæˆæ—¥**: {metadata.get('created_at', '')[:10]}")
                                            
                                            with result_col3:
                                                st.markdown("**ğŸ–¼ï¸ ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼**")
                                                try:
                                                    item_id = metadata['id']
                                                    image_file = images_dir / f"{item_id}.jpg"
                                                    if image_file.exists():
                                                        image = Image.open(image_file)
                                                        st.image(image, width=150)
                                                    else:
                                                        st.write("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
                                                except Exception as e:
                                                    st.write("ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸å¯")
                                            
                                            with result_col4:
                                                st.markdown("**ğŸ”— ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ **")
                                                item_id = metadata['id']
                                                st.write(f"**ãƒãƒ£ãƒ³ã‚¯**: `chunks/{item_id}.json`")
                                                st.write(f"**ãƒ™ã‚¯ãƒˆãƒ«**: `embeddings/{item_id}.json`")
                                                st.write(f"**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: `metadata/{item_id}.json`")
                                                st.write(f"**ç”»åƒ**: `images/{item_id}.jpg`")
                                            
                                            # è©³ç´°æƒ…å ±
                                            if display_meta.get('main_content'):
                                                st.markdown("**ğŸ“ å†…å®¹**")
                                                content = display_meta['main_content']
                                                st.write(content[:200] + '...' if len(content) > 200 else content)
                                            
                                            if display_meta.get('keywords'):
                                                st.markdown("**ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**")
                                                keywords = display_meta['keywords']
                                                keywords_display = ', '.join(keywords[:10])
                                                if len(keywords) > 10:
                                                    keywords_display += f" ï¼ˆä»–{len(keywords)-10}å€‹ï¼‰"
                                                st.write(keywords_display)
                                            
                                            if display_meta.get('purpose'):
                                                st.markdown("**ğŸ¯ ç”¨é€”**")
                                                st.write(display_meta['purpose'])
                                            
                                            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                                            if show_debug:
                                                with st.expander("ğŸ”§ ãƒ‡ãƒãƒƒã‚°: ãƒãƒ£ãƒ³ã‚¯ã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"):
                                                    st.markdown("**æ¤œç´¢ãƒãƒ£ãƒ³ã‚¯:**")
                                                    st.text_area("", chunk_data.get('content', ''), height=100, disabled=True, key=f"debug_chunk_{i}")
                                                    st.markdown("**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹:**")
                                                    st.write(f"chunks: {chunks_dir / f'{item_id}.json'}")
                                                    st.write(f"embeddings: {embeddings_dir / f'{item_id}.json'}")
                                                    st.write(f"metadata: {metadata_dir / f'{item_id}.json'}")
                                else:
                                    st.info("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢èªã‚’å¤‰æ›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
                            else:
                                st.error("âŒ æ¤œç´¢ã‚¯ã‚¨ãƒªã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    else:
                        st.error("âŒ OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æ¥ç¶šã§ãã¾ã›ã‚“")
        else:
            st.info("ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info(f"ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ '{kb_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
    if st.session_state.processed_images:
        st.subheader("ğŸ“ˆ ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ")
        
        total_images = len(st.session_state.processed_images)
        finalized_images = sum(1 for data in st.session_state.processed_images.values() 
                              if data.get('is_finalized', False))
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å‡¦ç†æ¸ˆã¿ç”»åƒ", total_images)
        with col2:
            st.metric("ç™»éŒ²æ¸ˆã¿", finalized_images)
        with col3:
            st.metric("æœªç™»éŒ²", total_images - finalized_images)
        with col4:
            st.metric("ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ", embedding_dims)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒŠãƒ¬ãƒƒã‚¸æ§‹ç¯‰ãƒ„ãƒ¼ãƒ« v3.0.0 - æ—¢å­˜RAGã‚·ã‚¹ãƒ†ãƒ çµ±åˆå¯¾å¿œç‰ˆ"
    "</div>", 
    unsafe_allow_html=True
)